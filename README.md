## Noise Conditional Score Network

This is a baseline 'reproduction' of the work [Generative Modeling by Estimating Gradients of theData Distribution](https://arxiv.org/pdf/1907.05600.pdf) by Song et al.

Here I use the MNIST dataset with a modified UNET network. The UNET decoder uses `Conditional Instance Normalization ++` from the paper to decode based on the input noise. This is not added to the encoder due to technical reasons.

### Dataset

| No noise added | Noise added |
|:--------------:|:-----------:|
|![img](samples/mnist_samples.png "Noiseless samples") | ![img](samples/mnist_noisy_samples.png "Noisy samples") |

### Samples generated by the trained diffusion model

| MNIST | CIFAR10 |
|:--------------:|:-----------:|
|![img](samples/mnist_model_samples.gif "MNIST NCSN samples") | ![img](samples/cifar10_model_samples.gif "CIFAR10 NCSN samples") |

```
@misc{qbeer,
  author       = {Alex Olar},
  title        = {Noise Conditional Score Network},
  howpublished = {GitHub repository},
  month        = {February},
  year         = {2023},
  url          = {https://github.com/qbeer/noisy_diffusion}
}
```
